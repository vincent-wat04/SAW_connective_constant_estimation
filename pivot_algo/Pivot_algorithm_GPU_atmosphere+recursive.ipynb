{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This notebook explores Pivot Algorithm with GPU (both Atmosphere Statistics method and Recursive Method)","metadata":{}},{"cell_type":"code","source":"!pip install cupy-cuda11x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T12:43:06.802649Z","iopub.execute_input":"2025-04-22T12:43:06.803168Z","iopub.status.idle":"2025-04-22T12:43:14.732487Z","shell.execute_reply.started":"2025-04-22T12:43:06.803141Z","shell.execute_reply":"2025-04-22T12:43:14.731647Z"}},"outputs":[{"name":"stdout","text":"Collecting cupy-cuda11x\n  Downloading cupy_cuda11x-13.4.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.7 kB)\nRequirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda11x) (1.26.4)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda11x) (0.8.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda11x) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3,>=1.22->cupy-cuda11x) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3,>=1.22->cupy-cuda11x) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22->cupy-cuda11x) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.3,>=1.22->cupy-cuda11x) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.3,>=1.22->cupy-cuda11x) (2024.2.0)\nDownloading cupy_cuda11x-13.4.1-cp311-cp311-manylinux2014_x86_64.whl (100.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: cupy-cuda11x\nSuccessfully installed cupy-cuda11x-13.4.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1. Atmosphere Statistics Method","metadata":{}},{"cell_type":"markdown","source":"### Key implementation details:\n1. common base thermolisation on CPU, then parallel pivot moves will be done to the base thermolised walk.\n2. max_trial: max trials pivot_move() will commit before it fails to generate a new SAW and returns the same walk. This prevents the appearance of many repetitive walks.\n3. pivot_steps_mode has 2 different modes, under 'multiple' mode, pivot moves will be executed for L times before samling the atmosphere value, to ensure the independence of $n$ sample from the base thermolised walk.\n4. uses cp.bincount() to achieve the collision check at computation time complexity = $O(N)$.\n5. the SAWs will be initialized at starting point (L_max, L_max) and the 2d coordinates will be mapped to positive integers to fullfil the prerequisites of cp.bincount() method.","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom tqdm import tqdm\nfrom scipy.optimize import curve_fit\n\n# CUDA kernel for parallel pivot move (no offset needed)\npivot_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid pivot_move_kernel(\n    int* walks,  // Flattened array: [num_samples, L+1, 2]\n    int num_samples, int L, int grid_size, int max_trial,\n    int* counts,  // Global array: [num_samples, grid_size * grid_size]\n    int* k_values,  // Random pivot points\n    int* g_values,  // Random symmetry operations\n    int* collision_flags  // Output: 1 if successful pivot, 0 if failed\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= num_samples) return;\n\n    int walk_offset = tid * (L + 1) * 2;  // the starting position of current thread's walk\n    int count_offset = tid * grid_size * grid_size;  // the starting position of current thread's count\n\n    // Get random pivot point and symmetry operation\n    int k = k_values[tid];\n    int g = g_values[tid];\n\n    // Try pivot move up to max_trial times\n    for (int trial = 0; trial < max_trial; trial++) {\n        // Copy walk to temporary array\n        int temp_walk[2002][2];\n        for (int i = 0; i <= L; i++) {\n            temp_walk[i][0] = walks[walk_offset + i * 2];\n            temp_walk[i][1] = walks[walk_offset + i * 2 + 1];\n        }\n\n        // Apply symmetry operation to subwalk (from k to L)\n        int pivot_x = temp_walk[k][0];\n        int pivot_y = temp_walk[k][1];\n        for (int i = k; i <= L; i++) {\n            int dx = temp_walk[i][0] - pivot_x;\n            int dy = temp_walk[i][1] - pivot_y;\n            if (g == 0) {  // rotate90\n                temp_walk[i][0] = pivot_x - dy;\n                temp_walk[i][1] = pivot_y + dx;\n            } else if (g == 1) {  // rotate180\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else if (g == 2) {  // reflect_x\n                temp_walk[i][0] = pivot_x + dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else {  // reflect_y\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y + dy;\n            }\n        }\n\n        // Collision check \n        bool has_collision = false;\n        for (int i = 0; i <= L; i++) {\n            int x = temp_walk[i][0];\n            int y = temp_walk[i][1];\n            if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n                has_collision = true;\n                break;\n            }\n            int idx = count_offset + (x * grid_size + y);\n            atomicAdd(&counts[idx], 1);\n            if (counts[idx] > 1) {\n                has_collision = true;\n                break;\n            }\n        }\n\n        // Reset counts and update walk if no collision\n        if (!has_collision) {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            for (int i = 0; i <= L; i++) {\n                walks[walk_offset + i * 2] = temp_walk[i][0];\n                walks[walk_offset + i * 2 + 1] = temp_walk[i][1];\n            }\n            collision_flags[tid] = 1;\n            return;\n        } else {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            // Update k and g for next trial\n            k = (k + 1) % (L - 1);\n            if (k == 0) k = 1;\n            g = (g + 1) % 4;\n        }\n    }\n    collision_flags[tid] = 0;\n}\n''', 'pivot_move_kernel')\n\n# CUDA kernel for parallel atmosphere calculation (no offset needed)\natmosphere_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid atmosphere_kernel(\n    int* walks,  // Flattened array: [num_samples, L+1, 2]\n    int num_samples, int L, int grid_size,\n    int* counts,  // Global array: [num_samples, grid_size * grid_size]\n    float* atm_counts  // Output: atmosphere counts for each walk\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= num_samples) return;\n\n    int walk_offset = tid * (L + 1) * 2;  // the starting position of current thread's walk\n    int count_offset = tid * grid_size * grid_size;  // the starting position of current thread's count\n\n    // Build counts for the walk\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        int idx = count_offset + (x * grid_size + y);\n        atomicAdd(&counts[idx], 1);\n    }\n\n    // Last point of the walk\n    int last_x = walks[walk_offset + L * 2];\n    int last_y = walks[walk_offset + L * 2 + 1];\n\n    // Check 4 directions\n    int atm_count = 0;\n    int directions[4][2] = {{1, 0}, {-1, 0}, {0, 1}, {0, -1}};\n    for (int d = 0; d < 4; d++) {\n        int new_x = last_x + directions[d][0];\n        int new_y = last_y + directions[d][1];\n        if (new_x < 0 || new_x >= grid_size || new_y < 0 || new_y >= grid_size) continue;\n        int idx = count_offset + (new_x * grid_size + new_y);\n        if (counts[idx] == 0) atm_count++;\n    }\n\n    // Reset counts\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        int idx = count_offset + (x * grid_size + y);\n        counts[idx] = 0;\n    }\n\n    atm_counts[tid] = (float)atm_count;\n}\n''', 'atmosphere_kernel')\n\nclass SAWSimulatorGPU:\n    def __init__(self, L_max=1000):\n        \"\"\"Initialize SAW simulator for 2D square lattice on GPU\"\"\"\n        self.directions = np.array([[1,0], [-1,0], [0,1], [0,-1]])  # Right, Left, Up, Down\n        self.L_max = L_max\n        self.grid_size = 2 * L_max + 1  # Grid size to accommodate coordinates [0, 2*L_max]\n        print(f\"Grid size: {self.grid_size}\")\n\n    def generate_initial_saw(self, L):\n        \"\"\"Create a single straight initial SAW starting at (L_max, L_max)\"\"\"\n        start_x, start_y = self.L_max, self.L_max\n        walk = np.array([[start_x + i, start_y] for i in range(L+1)], dtype=np.int32)\n        return walk\n\n    def generate_multiple_saws(self, base_walk, num_samples):\n        \"\"\"Create num_samples copies of the base walk\"\"\"\n        walks = np.tile(base_walk[np.newaxis, :, :], (num_samples, 1, 1))\n        return cp.array(walks)  # Shape: (num_samples, L+1, 2)\n\n    def pivot_move_single(self, walk, L, max_trial):\n        \"\"\"Perform a single pivot move on a single walk on CPU using np.bincount\"\"\"\n        for _ in range(max_trial):\n            k = np.random.randint(1, L)  # Random pivot point\n            g = np.random.randint(0, 4)  # Random symmetry operation (0: rotate90, 1: rotate180, 2: reflect_x, 3: reflect_y)\n\n            # Apply symmetry operation to subwalk\n            subwalk = walk[k:] - walk[k]\n            if g == 0:  # rotate90\n                transformed = np.array([[-y, x] for [x, y] in subwalk])\n            elif g == 1:  # rotate180\n                transformed = np.array([[-x, -y] for [x, y] in subwalk])\n            elif g == 2:  # reflect_x\n                transformed = np.array([[x, -y] for [x, y] in subwalk])\n            else:  # reflect_y\n                transformed = np.array([[-x, y] for [x, y] in subwalk])\n\n            new_walk = np.concatenate([walk[:k], walk[k] + transformed])\n\n            # Collision check using np.bincount on CPU\n            indices = new_walk[:, 0] * self.grid_size + new_walk[:, 1]\n            counts = np.bincount(indices, minlength=self.grid_size * self.grid_size)\n            if np.all(counts <= 1):\n                return new_walk, True\n\n        return walk, False\n\n    def pivot_move_parallel(self, walks, L, max_trial):\n        \"\"\"Perform pivot move on all walks in parallel using CUDA kernel\"\"\"\n        num_samples = walks.shape[0]\n        \n        walks = walks.astype(cp.int32)\n        walks_flat = walks.reshape(num_samples * (L + 1) * 2)\n        collision_flags = cp.zeros(num_samples, dtype=cp.int32)\n        \n        counts = cp.zeros(num_samples * self.grid_size * self.grid_size, dtype=cp.int32)\n\n        k_values = cp.random.randint(1, L, size=num_samples, dtype=cp.int32)\n        g_values = cp.random.randint(0, 4, size=num_samples, dtype=cp.int32)\n\n        threads_per_block = min(256, num_samples)\n        blocks_per_grid = (num_samples + threads_per_block - 1) // threads_per_block\n        \n        pivot_kernel(\n            (blocks_per_grid,), (threads_per_block,),\n            (walks_flat, num_samples, L, self.grid_size, max_trial, counts, k_values, g_values, collision_flags)\n        )\n\n        walks = walks_flat.reshape(num_samples, L + 1, 2)\n        return walks, collision_flags\n\n    def compute_atmosphere_parallel(self, walks, L, num_samples):\n        \"\"\"Compute atmosphere counts for all walks in parallel using CUDA kernel\"\"\"\n        walks_flat = walks.reshape(num_samples * (L + 1) * 2)\n        atm_counts = cp.zeros(num_samples, dtype=cp.float32)\n        counts = cp.zeros(num_samples * self.grid_size * self.grid_size, dtype=cp.int32)\n\n        threads_per_block = min(256, num_samples)\n        blocks_per_grid = (num_samples + threads_per_block - 1) // threads_per_block\n\n        atmosphere_kernel(\n            (blocks_per_grid,), (threads_per_block,),\n            (walks_flat, num_samples, L, self.grid_size, counts, atm_counts)\n        )\n\n        return atm_counts\n\n    def simulate_atmosphere(self, L, num_samples, max_trial, pivot_steps=1):\n        \"\"\"Estimate atmosphere statistics for walks of length L using GPU parallelization\n        pivot_steps: number of pivot moves per sample (1 or L)\n        \"\"\"\n        # Validate pivot_steps\n        if pivot_steps not in [1, L]:\n            raise ValueError(f\"pivot_steps must be 1 or L ({L}), got {pivot_steps}\")\n\n        # Generate a single initial walk\n        walk = self.generate_initial_saw(L)\n        \n        # Thermalization (burn-in) on a single walk on CPU\n        for _ in range(10 * L):\n            walk, _ = self.pivot_move_single(walk, L, max_trial)\n        \n        # Generate num_samples copies of the thermalized walk\n        walks = self.generate_multiple_saws(walk, num_samples)\n\n        # Production run: perform pivot_steps pivot moves per walk\n        for _ in range(pivot_steps):\n            walks, _ = self.pivot_move_parallel(walks, L, max_trial)\n        \n        # Compute atmosphere for all walks\n        atm_counts = self.compute_atmosphere_parallel(walks, L, num_samples)\n        \n        atm_counts = atm_counts.get()\n        return np.mean(atm_counts), np.std(atm_counts) / np.sqrt(len(atm_counts))\n    \n    def estimate_mu(self, num_samples=10000, max_trial=10, pivot_steps_mode='single'):\n        \"\"\"Estimate μ using atmosphere statistics\n        max_trial: max trials before pivot_move() fails to generate a new SAW and returns the same walk \n        pivot_steps_mode: 'single' (1 pivot) or 'multiple' (L pivots)\n        \"\"\"\n        lengths = np.arange(4, self.L_max+1, 2)\n        atm_means = []\n        atm_stds = []\n        \n        print(\"Running SAW simulations for μ estimation on GPU...\")\n        start = time()\n        for L in tqdm(lengths):\n            pivot_steps = 1 if pivot_steps_mode == 'single' else L\n            mean_atm, std_atm = self.simulate_atmosphere(L, num_samples, max_trial, pivot_steps=pivot_steps)\n            atm_means.append(mean_atm)\n            atm_stds.append(std_atm)\n            print(f\"L={L}: ⟨a⟩ = {mean_atm:.3f} ± {std_atm:.3f}\")\n        end = time()\n        \n        atm_means = np.array(atm_means)\n        atm_stds = np.array(atm_stds)\n        def model(n, mu, gamma, c):\n            return mu * (1 + (gamma-1)/n + c/n**2)\n        \n        popt, pcov = curve_fit(model, lengths, atm_means)\n        mu, gamma = popt[0], popt[1]\n        \n        # Plot 1: <a> vs L\n        plt.figure(figsize=(10,6))\n        plt.scatter(lengths, atm_means, label='Simulation Data')\n        x_fit = np.linspace(lengths[0], lengths[-1], 100)\n        plt.plot(x_fit, model(x_fit, *popt), 'r-', \n                label=f'Fit: μ={mu:.6f}, γ={gamma:.6f}')\n        plt.xlabel('L')\n        plt.ylabel('<a>')\n        plt.title(f'Atmosphere Statistics for 2D SAWs (GPU Parallel), N={num_samples}, Time={end-start:.2f}s, mu~{mu:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig(f'saw_mu_estimation_gpu_parallel_L_{pivot_steps_mode}.png', dpi=300)\n        plt.close()\n        \n        # Plot 2: <a> vs 1/L with benchmark mu\n        benchmark_mu = 2.638158  # Theoretical mu for 2D SAW\n        inv_lengths = 1 / lengths\n        plt.figure(figsize=(10,6))\n        plt.scatter(inv_lengths, atm_means, label='Simulation Data')\n        x_fit_inv = np.linspace(0, inv_lengths[0], 100)\n        plt.plot(x_fit_inv, model(1/x_fit_inv, *popt), 'r-', \n                label=f'Fit: μ={mu:.6f}, γ={gamma:.6f}')\n        plt.axhline(y=benchmark_mu, color='g', linestyle='--', label=f'Benchmark μ={benchmark_mu:.6f}')\n        plt.xlabel('1/L')\n        plt.ylabel('<a>')\n        plt.title(f'Atmosphere Statistics for 2D SAWs: Convergence to μ (GPU Parallel), N={num_samples}, Time={end-start:.2f}s, mu~{mu:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig(f'saw_mu_estimation_gpu_parallel_inv_L_{pivot_steps_mode}.png', dpi=300)\n        plt.close()\n        \n        return mu, gamma\n\n# Benchmarking\nif __name__ == \"__main__\":\n    simulator = SAWSimulatorGPU(L_max=200)\n    \n    # Test both modes\n    for mode in ['single', 'multiple']:\n        print(f\"\\nTesting mode: {mode}\")\n        start_time = time()\n        mu, gamma = simulator.estimate_mu(num_samples=10000, max_trial=10, pivot_steps_mode=mode)\n        gpu_time = time() - start_time\n        \n        print(f\"GPU Parallel Version Results (Mode: {mode}):\")\n        print(f\"Estimated μ = {mu:.6f}\")\n        print(f\"Estimated γ = {gamma:.6f}\")\n        print(f\"Computation Time = {gpu_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T00:28:54.487859Z","iopub.execute_input":"2025-04-25T00:28:54.488362Z","iopub.status.idle":"2025-04-25T00:35:59.586709Z","shell.execute_reply.started":"2025-04-25T00:28:54.488337Z","shell.execute_reply":"2025-04-25T00:35:59.585957Z"}},"outputs":[{"name":"stdout","text":"Grid size: 401\n\nTesting mode: single\nRunning SAW simulations for μ estimation on GPU...\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 3/99 [00:02<00:51,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"L=4: ⟨a⟩ = 2.753 ± 0.004\nL=6: ⟨a⟩ = 3.000 ± 0.000\nL=8: ⟨a⟩ = 2.931 ± 0.003\nL=10: ⟨a⟩ = 2.832 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 7/99 [00:02<00:19,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"L=12: ⟨a⟩ = 2.797 ± 0.005\nL=14: ⟨a⟩ = 2.980 ± 0.001\nL=16: ⟨a⟩ = 2.963 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 9/99 [00:02<00:15,  6.00it/s]","output_type":"stream"},{"name":"stdout","text":"L=18: ⟨a⟩ = 3.000 ± 0.000\nL=20: ⟨a⟩ = 2.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 11/99 [00:02<00:13,  6.53it/s]","output_type":"stream"},{"name":"stdout","text":"L=22: ⟨a⟩ = 2.037 ± 0.003\nL=24: ⟨a⟩ = 2.989 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 13/99 [00:03<00:12,  6.67it/s]","output_type":"stream"},{"name":"stdout","text":"L=26: ⟨a⟩ = 2.068 ± 0.003\nL=28: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 15/99 [00:03<00:13,  6.23it/s]","output_type":"stream"},{"name":"stdout","text":"L=30: ⟨a⟩ = 2.983 ± 0.002\nL=32: ⟨a⟩ = 2.901 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 16/99 [00:03<00:14,  5.92it/s]","output_type":"stream"},{"name":"stdout","text":"L=34: ⟨a⟩ = 2.970 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 17/99 [00:03<00:14,  5.53it/s]","output_type":"stream"},{"name":"stdout","text":"L=36: ⟨a⟩ = 2.993 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 18/99 [00:04<00:15,  5.36it/s]","output_type":"stream"},{"name":"stdout","text":"L=38: ⟨a⟩ = 2.969 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 19/99 [00:04<00:15,  5.01it/s]","output_type":"stream"},{"name":"stdout","text":"L=40: ⟨a⟩ = 1.796 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 20/99 [00:04<00:17,  4.60it/s]","output_type":"stream"},{"name":"stdout","text":"L=42: ⟨a⟩ = 2.642 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 21/99 [00:04<00:17,  4.35it/s]","output_type":"stream"},{"name":"stdout","text":"L=44: ⟨a⟩ = 2.981 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 22/99 [00:05<00:18,  4.08it/s]","output_type":"stream"},{"name":"stdout","text":"L=46: ⟨a⟩ = 2.976 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 23/99 [00:05<00:19,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"L=48: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 24/99 [00:05<00:20,  3.73it/s]","output_type":"stream"},{"name":"stdout","text":"L=50: ⟨a⟩ = 2.954 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 25/99 [00:06<00:21,  3.50it/s]","output_type":"stream"},{"name":"stdout","text":"L=52: ⟨a⟩ = 2.948 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▋       | 26/99 [00:06<00:22,  3.28it/s]","output_type":"stream"},{"name":"stdout","text":"L=54: ⟨a⟩ = 1.572 ± 0.013\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 27/99 [00:06<00:22,  3.18it/s]","output_type":"stream"},{"name":"stdout","text":"L=56: ⟨a⟩ = 2.966 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 28/99 [00:07<00:23,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"L=58: ⟨a⟩ = 1.104 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 29/99 [00:07<00:24,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"L=60: ⟨a⟩ = 2.994 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 30/99 [00:07<00:25,  2.71it/s]","output_type":"stream"},{"name":"stdout","text":"L=62: ⟨a⟩ = 2.992 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 31/99 [00:08<00:26,  2.61it/s]","output_type":"stream"},{"name":"stdout","text":"L=64: ⟨a⟩ = 2.980 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 32/99 [00:08<00:26,  2.50it/s]","output_type":"stream"},{"name":"stdout","text":"L=66: ⟨a⟩ = 2.822 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 33/99 [00:09<00:27,  2.41it/s]","output_type":"stream"},{"name":"stdout","text":"L=68: ⟨a⟩ = 2.993 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 34/99 [00:09<00:28,  2.30it/s]","output_type":"stream"},{"name":"stdout","text":"L=70: ⟨a⟩ = 2.968 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 35/99 [00:10<00:28,  2.23it/s]","output_type":"stream"},{"name":"stdout","text":"L=72: ⟨a⟩ = 2.977 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 36/99 [00:10<00:29,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"L=74: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 37/99 [00:11<00:30,  2.01it/s]","output_type":"stream"},{"name":"stdout","text":"L=76: ⟨a⟩ = 1.998 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 38/99 [00:11<00:31,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"L=78: ⟨a⟩ = 2.975 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 39/99 [00:12<00:31,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"L=80: ⟨a⟩ = 2.979 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 40/99 [00:12<00:32,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"L=82: ⟨a⟩ = 2.995 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 41/99 [00:13<00:31,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"L=84: ⟨a⟩ = 2.032 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 42/99 [00:14<00:32,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"L=86: ⟨a⟩ = 2.930 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 43/99 [00:14<00:33,  1.65it/s]","output_type":"stream"},{"name":"stdout","text":"L=88: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 44/99 [00:15<00:34,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"L=90: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 45/99 [00:16<00:34,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"L=92: ⟨a⟩ = 2.958 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 46/99 [00:16<00:34,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"L=94: ⟨a⟩ = 2.026 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 47/99 [00:17<00:35,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"L=96: ⟨a⟩ = 2.965 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 48/99 [00:18<00:35,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"L=98: ⟨a⟩ = 2.994 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 49/99 [00:19<00:35,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"L=100: ⟨a⟩ = 1.074 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 50/99 [00:19<00:35,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"L=102: ⟨a⟩ = 1.997 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 51/99 [00:20<00:37,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"L=104: ⟨a⟩ = 2.928 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 52/99 [00:21<00:37,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"L=106: ⟨a⟩ = 1.968 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 53/99 [00:22<00:37,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"L=108: ⟨a⟩ = 2.932 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 54/99 [00:23<00:36,  1.22it/s]","output_type":"stream"},{"name":"stdout","text":"L=110: ⟨a⟩ = 2.986 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 55/99 [00:24<00:37,  1.18it/s]","output_type":"stream"},{"name":"stdout","text":"L=112: ⟨a⟩ = 1.111 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 56/99 [00:25<00:37,  1.14it/s]","output_type":"stream"},{"name":"stdout","text":"L=114: ⟨a⟩ = 2.018 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 57/99 [00:26<00:37,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"L=116: ⟨a⟩ = 2.966 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▊    | 58/99 [00:27<00:37,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"L=118: ⟨a⟩ = 2.965 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 59/99 [00:28<00:37,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"L=120: ⟨a⟩ = 2.982 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 60/99 [00:29<00:38,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"L=122: ⟨a⟩ = 2.984 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 61/99 [00:30<00:37,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"L=124: ⟨a⟩ = 2.953 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 62/99 [00:31<00:37,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"L=126: ⟨a⟩ = 2.997 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▎   | 63/99 [00:32<00:37,  1.04s/it]","output_type":"stream"},{"name":"stdout","text":"L=128: ⟨a⟩ = 2.977 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 64/99 [00:33<00:37,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"L=130: ⟨a⟩ = 2.967 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 65/99 [00:34<00:37,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"L=132: ⟨a⟩ = 2.276 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 66/99 [00:35<00:37,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"L=134: ⟨a⟩ = 2.987 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 67/99 [00:36<00:36,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"L=136: ⟨a⟩ = 2.170 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▊   | 68/99 [00:38<00:36,  1.18s/it]","output_type":"stream"},{"name":"stdout","text":"L=138: ⟨a⟩ = 2.987 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 69/99 [00:39<00:35,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"L=140: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 70/99 [00:40<00:35,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"L=142: ⟨a⟩ = 2.994 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 71/99 [00:42<00:35,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"L=144: ⟨a⟩ = 2.012 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 72/99 [00:43<00:34,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"L=146: ⟨a⟩ = 2.960 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▎  | 73/99 [00:44<00:33,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"L=148: ⟨a⟩ = 2.016 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 74/99 [00:46<00:33,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"L=150: ⟨a⟩ = 1.998 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 75/99 [00:47<00:32,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"L=152: ⟨a⟩ = 2.984 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 76/99 [00:48<00:31,  1.36s/it]","output_type":"stream"},{"name":"stdout","text":"L=154: ⟨a⟩ = 2.989 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 77/99 [00:50<00:31,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"L=156: ⟨a⟩ = 2.996 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 78/99 [00:51<00:30,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"L=158: ⟨a⟩ = 2.995 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 79/99 [00:53<00:29,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"L=160: ⟨a⟩ = 2.974 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 80/99 [00:54<00:27,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"L=162: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 81/99 [00:56<00:27,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"L=164: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 82/99 [00:58<00:26,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"L=166: ⟨a⟩ = 2.993 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 83/99 [00:59<00:25,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"L=168: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 84/99 [01:01<00:24,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"L=170: ⟨a⟩ = 2.027 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 85/99 [01:03<00:22,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"L=172: ⟨a⟩ = 2.999 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 86/99 [01:04<00:21,  1.67s/it]","output_type":"stream"},{"name":"stdout","text":"L=174: ⟨a⟩ = 2.924 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 87/99 [01:06<00:20,  1.71s/it]","output_type":"stream"},{"name":"stdout","text":"L=176: ⟨a⟩ = 2.986 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 88/99 [01:08<00:19,  1.73s/it]","output_type":"stream"},{"name":"stdout","text":"L=178: ⟨a⟩ = 2.145 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 89/99 [01:10<00:17,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"L=180: ⟨a⟩ = 2.914 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 90/99 [01:12<00:16,  1.81s/it]","output_type":"stream"},{"name":"stdout","text":"L=182: ⟨a⟩ = 2.003 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 91/99 [01:14<00:14,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"L=184: ⟨a⟩ = 2.995 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 92/99 [01:16<00:12,  1.85s/it]","output_type":"stream"},{"name":"stdout","text":"L=186: ⟨a⟩ = 2.011 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 93/99 [01:17<00:11,  1.88s/it]","output_type":"stream"},{"name":"stdout","text":"L=188: ⟨a⟩ = 2.986 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 94/99 [01:19<00:09,  1.90s/it]","output_type":"stream"},{"name":"stdout","text":"L=190: ⟨a⟩ = 1.998 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 95/99 [01:21<00:07,  1.93s/it]","output_type":"stream"},{"name":"stdout","text":"L=192: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 96/99 [01:23<00:05,  1.94s/it]","output_type":"stream"},{"name":"stdout","text":"L=194: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 97/99 [01:25<00:03,  1.97s/it]","output_type":"stream"},{"name":"stdout","text":"L=196: ⟨a⟩ = 1.050 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 98/99 [01:28<00:02,  2.01s/it]","output_type":"stream"},{"name":"stdout","text":"L=198: ⟨a⟩ = 2.982 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [01:30<00:00,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"L=200: ⟨a⟩ = 2.973 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":"\n/tmp/ipykernel_31/1018378718.py:318: RuntimeWarning: divide by zero encountered in divide\n  plt.plot(x_fit_inv, model(1/x_fit_inv, *popt), 'r-',\n","output_type":"stream"},{"name":"stdout","text":"GPU Parallel Version Results (Mode: single):\nEstimated μ = 2.641129\nEstimated γ = 2.006950\nComputation Time = 91.22 seconds\n\nTesting mode: multiple\nRunning SAW simulations for μ estimation on GPU...\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 2/99 [00:00<00:08, 11.52it/s]","output_type":"stream"},{"name":"stdout","text":"L=4: ⟨a⟩ = 2.840 ± 0.004\nL=6: ⟨a⟩ = 2.947 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 4/99 [00:00<00:11,  8.08it/s]","output_type":"stream"},{"name":"stdout","text":"L=8: ⟨a⟩ = 2.607 ± 0.006\nL=10: ⟨a⟩ = 2.918 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 5/99 [00:00<00:13,  6.84it/s]","output_type":"stream"},{"name":"stdout","text":"L=12: ⟨a⟩ = 2.918 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 6/99 [00:00<00:15,  5.83it/s]","output_type":"stream"},{"name":"stdout","text":"L=14: ⟨a⟩ = 2.900 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 7/99 [00:01<00:18,  5.08it/s]","output_type":"stream"},{"name":"stdout","text":"L=16: ⟨a⟩ = 2.515 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 8/99 [00:01<00:20,  4.43it/s]","output_type":"stream"},{"name":"stdout","text":"L=18: ⟨a⟩ = 2.774 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 9/99 [00:01<00:23,  3.89it/s]","output_type":"stream"},{"name":"stdout","text":"L=20: ⟨a⟩ = 2.481 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 10/99 [00:02<00:26,  3.39it/s]","output_type":"stream"},{"name":"stdout","text":"L=22: ⟨a⟩ = 2.790 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 11/99 [00:02<00:28,  3.04it/s]","output_type":"stream"},{"name":"stdout","text":"L=24: ⟨a⟩ = 2.530 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 12/99 [00:03<00:32,  2.71it/s]","output_type":"stream"},{"name":"stdout","text":"L=26: ⟨a⟩ = 2.697 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 13/99 [00:03<00:35,  2.45it/s]","output_type":"stream"},{"name":"stdout","text":"L=28: ⟨a⟩ = 2.875 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 14/99 [00:04<00:37,  2.25it/s]","output_type":"stream"},{"name":"stdout","text":"L=30: ⟨a⟩ = 2.882 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 15/99 [00:04<00:40,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"L=32: ⟨a⟩ = 2.531 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 16/99 [00:05<00:43,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"L=34: ⟨a⟩ = 2.775 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 17/99 [00:05<00:47,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"L=36: ⟨a⟩ = 2.680 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 18/99 [00:06<00:50,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"L=38: ⟨a⟩ = 2.785 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 19/99 [00:07<00:53,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"L=40: ⟨a⟩ = 2.616 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 20/99 [00:08<00:55,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"L=42: ⟨a⟩ = 2.806 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 21/99 [00:09<00:58,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"L=44: ⟨a⟩ = 2.577 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 22/99 [00:10<01:01,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"L=46: ⟨a⟩ = 2.578 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 23/99 [00:10<01:04,  1.18it/s]","output_type":"stream"},{"name":"stdout","text":"L=48: ⟨a⟩ = 2.534 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 24/99 [00:12<01:07,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"L=50: ⟨a⟩ = 2.530 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 25/99 [00:13<01:09,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"L=52: ⟨a⟩ = 2.538 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▋       | 26/99 [00:14<01:12,  1.01it/s]","output_type":"stream"},{"name":"stdout","text":"L=54: ⟨a⟩ = 2.840 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 27/99 [00:15<01:15,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"L=56: ⟨a⟩ = 2.660 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 28/99 [00:16<01:17,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"L=58: ⟨a⟩ = 2.815 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 29/99 [00:17<01:21,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"L=60: ⟨a⟩ = 2.436 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 30/99 [00:19<01:24,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"L=62: ⟨a⟩ = 2.726 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 31/99 [00:20<01:27,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"L=64: ⟨a⟩ = 2.887 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 32/99 [00:22<01:29,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"L=66: ⟨a⟩ = 2.869 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 33/99 [00:23<01:32,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"L=68: ⟨a⟩ = 2.562 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 34/99 [00:25<01:34,  1.46s/it]","output_type":"stream"},{"name":"stdout","text":"L=70: ⟨a⟩ = 2.529 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 35/99 [00:26<01:37,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"L=72: ⟨a⟩ = 2.547 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 36/99 [00:28<01:39,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"L=74: ⟨a⟩ = 2.811 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 37/99 [00:30<01:42,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"L=76: ⟨a⟩ = 2.420 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 38/99 [00:32<01:44,  1.72s/it]","output_type":"stream"},{"name":"stdout","text":"L=78: ⟨a⟩ = 2.829 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 39/99 [00:34<01:46,  1.78s/it]","output_type":"stream"},{"name":"stdout","text":"L=80: ⟨a⟩ = 2.543 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 40/99 [00:36<01:48,  1.84s/it]","output_type":"stream"},{"name":"stdout","text":"L=82: ⟨a⟩ = 2.685 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 41/99 [00:38<01:50,  1.91s/it]","output_type":"stream"},{"name":"stdout","text":"L=84: ⟨a⟩ = 2.495 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 42/99 [00:40<01:52,  1.98s/it]","output_type":"stream"},{"name":"stdout","text":"L=86: ⟨a⟩ = 2.532 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 43/99 [00:42<01:55,  2.07s/it]","output_type":"stream"},{"name":"stdout","text":"L=88: ⟨a⟩ = 2.704 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 44/99 [00:45<01:58,  2.15s/it]","output_type":"stream"},{"name":"stdout","text":"L=90: ⟨a⟩ = 2.845 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 45/99 [00:47<02:00,  2.23s/it]","output_type":"stream"},{"name":"stdout","text":"L=92: ⟨a⟩ = 2.786 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 46/99 [00:50<02:02,  2.32s/it]","output_type":"stream"},{"name":"stdout","text":"L=94: ⟨a⟩ = 2.857 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 47/99 [00:52<02:03,  2.38s/it]","output_type":"stream"},{"name":"stdout","text":"L=96: ⟨a⟩ = 2.845 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 48/99 [00:55<02:05,  2.46s/it]","output_type":"stream"},{"name":"stdout","text":"L=98: ⟨a⟩ = 2.784 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 49/99 [00:57<02:06,  2.53s/it]","output_type":"stream"},{"name":"stdout","text":"L=100: ⟨a⟩ = 2.635 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 50/99 [01:00<02:07,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"L=102: ⟨a⟩ = 2.547 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 51/99 [01:03<02:08,  2.67s/it]","output_type":"stream"},{"name":"stdout","text":"L=104: ⟨a⟩ = 2.566 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 52/99 [01:06<02:09,  2.75s/it]","output_type":"stream"},{"name":"stdout","text":"L=106: ⟨a⟩ = 2.761 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▎    | 53/99 [01:09<02:09,  2.82s/it]","output_type":"stream"},{"name":"stdout","text":"L=108: ⟨a⟩ = 2.833 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▍    | 54/99 [01:12<02:12,  2.94s/it]","output_type":"stream"},{"name":"stdout","text":"L=110: ⟨a⟩ = 2.725 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 55/99 [01:15<02:13,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"L=112: ⟨a⟩ = 2.710 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 56/99 [01:19<02:13,  3.10s/it]","output_type":"stream"},{"name":"stdout","text":"L=114: ⟨a⟩ = 2.701 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 57/99 [01:22<02:14,  3.19s/it]","output_type":"stream"},{"name":"stdout","text":"L=116: ⟨a⟩ = 2.529 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▊    | 58/99 [01:26<02:15,  3.30s/it]","output_type":"stream"},{"name":"stdout","text":"L=118: ⟨a⟩ = 2.862 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 60%|█████▉    | 59/99 [01:29<02:14,  3.37s/it]","output_type":"stream"},{"name":"stdout","text":"L=120: ⟨a⟩ = 2.638 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 60/99 [01:33<02:15,  3.48s/it]","output_type":"stream"},{"name":"stdout","text":"L=122: ⟨a⟩ = 2.771 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 61/99 [01:37<02:16,  3.58s/it]","output_type":"stream"},{"name":"stdout","text":"L=124: ⟨a⟩ = 2.586 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 62/99 [01:41<02:16,  3.69s/it]","output_type":"stream"},{"name":"stdout","text":"L=126: ⟨a⟩ = 2.763 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▎   | 63/99 [01:45<02:15,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"L=128: ⟨a⟩ = 2.383 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 64/99 [01:49<02:15,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"L=130: ⟨a⟩ = 2.589 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 65/99 [01:53<02:15,  3.98s/it]","output_type":"stream"},{"name":"stdout","text":"L=132: ⟨a⟩ = 2.758 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 66/99 [01:57<02:14,  4.09s/it]","output_type":"stream"},{"name":"stdout","text":"L=134: ⟨a⟩ = 2.843 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 67/99 [02:02<02:13,  4.17s/it]","output_type":"stream"},{"name":"stdout","text":"L=136: ⟨a⟩ = 2.575 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▊   | 68/99 [02:06<02:13,  4.31s/it]","output_type":"stream"},{"name":"stdout","text":"L=138: ⟨a⟩ = 2.549 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 69/99 [02:11<02:12,  4.43s/it]","output_type":"stream"},{"name":"stdout","text":"L=140: ⟨a⟩ = 2.630 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 70/99 [02:16<02:12,  4.57s/it]","output_type":"stream"},{"name":"stdout","text":"L=142: ⟨a⟩ = 2.670 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 71/99 [02:21<02:10,  4.67s/it]","output_type":"stream"},{"name":"stdout","text":"L=144: ⟨a⟩ = 2.551 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 72/99 [02:26<02:08,  4.75s/it]","output_type":"stream"},{"name":"stdout","text":"L=146: ⟨a⟩ = 2.417 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▎  | 73/99 [02:31<02:05,  4.84s/it]","output_type":"stream"},{"name":"stdout","text":"L=148: ⟨a⟩ = 2.460 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 74/99 [02:36<02:03,  4.94s/it]","output_type":"stream"},{"name":"stdout","text":"L=150: ⟨a⟩ = 2.760 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 75/99 [02:41<02:01,  5.05s/it]","output_type":"stream"},{"name":"stdout","text":"L=152: ⟨a⟩ = 2.793 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 76/99 [02:47<01:58,  5.16s/it]","output_type":"stream"},{"name":"stdout","text":"L=154: ⟨a⟩ = 2.833 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 77/99 [02:52<01:56,  5.31s/it]","output_type":"stream"},{"name":"stdout","text":"L=156: ⟨a⟩ = 2.851 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 78/99 [02:58<01:54,  5.44s/it]","output_type":"stream"},{"name":"stdout","text":"L=158: ⟨a⟩ = 2.659 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 80%|███████▉  | 79/99 [03:04<01:51,  5.55s/it]","output_type":"stream"},{"name":"stdout","text":"L=160: ⟨a⟩ = 2.499 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 80/99 [03:10<01:47,  5.67s/it]","output_type":"stream"},{"name":"stdout","text":"L=162: ⟨a⟩ = 2.460 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 81/99 [03:16<01:44,  5.78s/it]","output_type":"stream"},{"name":"stdout","text":"L=164: ⟨a⟩ = 2.701 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 82/99 [03:22<01:40,  5.90s/it]","output_type":"stream"},{"name":"stdout","text":"L=166: ⟨a⟩ = 2.411 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 83/99 [03:28<01:36,  6.05s/it]","output_type":"stream"},{"name":"stdout","text":"L=168: ⟨a⟩ = 2.783 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▍ | 84/99 [03:35<01:32,  6.16s/it]","output_type":"stream"},{"name":"stdout","text":"L=170: ⟨a⟩ = 2.727 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 85/99 [03:41<01:27,  6.29s/it]","output_type":"stream"},{"name":"stdout","text":"L=172: ⟨a⟩ = 2.545 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 86/99 [03:48<01:23,  6.43s/it]","output_type":"stream"},{"name":"stdout","text":"L=174: ⟨a⟩ = 2.801 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 87/99 [03:55<01:18,  6.56s/it]","output_type":"stream"},{"name":"stdout","text":"L=176: ⟨a⟩ = 2.768 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 88/99 [04:02<01:14,  6.81s/it]","output_type":"stream"},{"name":"stdout","text":"L=178: ⟨a⟩ = 2.846 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 89/99 [04:10<01:09,  6.94s/it]","output_type":"stream"},{"name":"stdout","text":"L=180: ⟨a⟩ = 2.852 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 90/99 [04:17<01:03,  7.04s/it]","output_type":"stream"},{"name":"stdout","text":"L=182: ⟨a⟩ = 2.425 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 91/99 [04:24<00:56,  7.11s/it]","output_type":"stream"},{"name":"stdout","text":"L=184: ⟨a⟩ = 2.395 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 92/99 [04:32<00:50,  7.24s/it]","output_type":"stream"},{"name":"stdout","text":"L=186: ⟨a⟩ = 2.572 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 93/99 [04:39<00:44,  7.38s/it]","output_type":"stream"},{"name":"stdout","text":"L=188: ⟨a⟩ = 2.547 ± 0.007\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 94/99 [04:47<00:37,  7.56s/it]","output_type":"stream"},{"name":"stdout","text":"L=190: ⟨a⟩ = 2.652 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 95/99 [04:55<00:30,  7.70s/it]","output_type":"stream"},{"name":"stdout","text":"L=192: ⟨a⟩ = 2.405 ± 0.008\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 96/99 [05:04<00:23,  7.84s/it]","output_type":"stream"},{"name":"stdout","text":"L=194: ⟨a⟩ = 2.852 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 97/99 [05:12<00:15,  7.95s/it]","output_type":"stream"},{"name":"stdout","text":"L=196: ⟨a⟩ = 2.592 ± 0.006\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 98/99 [05:20<00:08,  8.14s/it]","output_type":"stream"},{"name":"stdout","text":"L=198: ⟨a⟩ = 2.856 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 99/99 [05:29<00:00,  3.33s/it]","output_type":"stream"},{"name":"stdout","text":"L=200: ⟨a⟩ = 2.826 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"GPU Parallel Version Results (Mode: multiple):\nEstimated μ = 2.646908\nEstimated γ = 1.646891\nComputation Time = 330.74 seconds\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"The variable 'counts' is of $numSamples \\times gridSize^2 \\times 4$, thus the simulation will fail when large numSamples and gridSize make the size of 'counts' exceed GPU's memory.\n\nAgain, we use batch execution to solve this issue.","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom tqdm import tqdm\nfrom scipy.optimize import curve_fit\n\n# CUDA kernel for parallel pivot move (no offset needed)\npivot_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid pivot_move_kernel(\n    int* walks,  // Flattened array: [batch_size, L+1, 2]\n    int batch_size, int L, int grid_size, int max_trial,\n    int* counts,  // Global array: [batch_size, grid_size * grid_size]\n    int* k_values,  // Random pivot points\n    int* g_values,  // Random symmetry operations\n    int* collision_flags  // Output: 1 if successful pivot, 0 if failed\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= batch_size) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Get random pivot point and symmetry operation\n    int k = k_values[tid];\n    int g = g_values[tid];\n\n    // Try pivot move up to max_trial times\n    for (int trial = 0; trial < max_trial; trial++) {\n        // Copy walk to temporary array\n        int temp_walk[2002][2];  // Increased size to accommodate L_max=1000\n        for (int i = 0; i <= L; i++) {\n            temp_walk[i][0] = walks[walk_offset + i * 2];\n            temp_walk[i][1] = walks[walk_offset + i * 2 + 1];\n        }\n\n        // Apply symmetry operation to subwalk (from k to L)\n        int pivot_x = temp_walk[k][0];\n        int pivot_y = temp_walk[k][1];\n        for (int i = k; i <= L; i++) {\n            int dx = temp_walk[i][0] - pivot_x;\n            int dy = temp_walk[i][1] - pivot_y;\n            if (g == 0) {  // rotate90\n                temp_walk[i][0] = pivot_x - dy;\n                temp_walk[i][1] = pivot_y + dx;\n            } else if (g == 1) {  // rotate180\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else if (g == 2) {  // reflect_x\n                temp_walk[i][0] = pivot_x + dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else {  // reflect_y\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y + dy;\n            }\n        }\n\n        // Collision check \n        bool has_collision = false;\n        for (int i = 0; i <= L; i++) {\n            int x = temp_walk[i][0];\n            int y = temp_walk[i][1];\n            if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n                has_collision = true;\n                break;\n            }\n            int idx = count_offset + (x * grid_size + y);\n            atomicAdd(&counts[idx], 1);\n            if (counts[idx] > 1) {\n                has_collision = true;\n                break;\n            }\n        }\n\n        // Reset counts and update walk if no collision\n        if (!has_collision) {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            for (int i = 0; i <= L; i++) {\n                walks[walk_offset + i * 2] = temp_walk[i][0];\n                walks[walk_offset + i * 2 + 1] = temp_walk[i][1];\n            }\n            collision_flags[tid] = 1;\n            return;\n        } else {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            // Update k and g for next trial\n            k = (k + 1) % (L - 1);\n            if (k == 0) k = 1;\n            g = (g + 1) % 4;\n        }\n    }\n    collision_flags[tid] = 0;\n}\n''', 'pivot_move_kernel')\n\n# CUDA kernel for parallel atmosphere calculation (no offset needed)\natmosphere_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid atmosphere_kernel(\n    int* walks,  // Flattened array: [batch_size, L+1, 2]\n    int batch_size, int L, int grid_size,\n    int* counts,  // Global array: [batch_size, grid_size * grid_size]\n    float* atm_counts  // Output: atmosphere counts for each walk\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= batch_size) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Build counts for the walk\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        int idx = count_offset + (x * grid_size + y);\n        atomicAdd(&counts[idx], 1);\n    }\n\n    // Last point of the walk\n    int last_x = walks[walk_offset + L * 2];\n    int last_y = walks[walk_offset + L * 2 + 1];\n\n    // Check 4 directions\n    int atm_count = 0;\n    int directions[4][2] = {{1, 0}, {-1, 0}, {0, 1}, {0, -1}};\n    for (int d = 0; d < 4; d++) {\n        int new_x = last_x + directions[d][0];\n        int new_y = last_y + directions[d][1];\n        if (new_x < 0 || new_x >= grid_size || new_y < 0 || new_y >= grid_size) continue;\n        int idx = count_offset + (new_x * grid_size + new_y);\n        if (counts[idx] == 0) atm_count++;\n    }\n\n    // Reset counts\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        int idx = count_offset + (x * grid_size + y);\n        counts[idx] = 0;\n    }\n\n    atm_counts[tid] = (float)atm_count;\n}\n''', 'atmosphere_kernel')\n\nclass SAWSimulatorGPU:\n    def __init__(self, L_max=1000):\n        \"\"\"Initialize SAW simulator for 2D square lattice on GPU\"\"\"\n        self.directions = np.array([[1,0], [-1,0], [0,1], [0,-1]])  # Right, Left, Up, Down\n        self.L_max = L_max\n        self.grid_size = 2 * L_max + 1  # Grid size to accommodate coordinates [0, 2*L_max]\n        self.batch_size = 256  # Set batch size to a reasonable value\n        print(f\"Grid size: {self.grid_size}, Batch size: {self.batch_size}\")\n\n    def generate_initial_saw(self, L):\n        \"\"\"Create a single straight initial SAW starting at (L_max, L_max)\"\"\"\n        start_x, start_y = self.L_max, self.L_max\n        walk = np.array([[start_x + i, start_y] for i in range(L+1)], dtype=np.int32)\n        return walk\n\n    def generate_multiple_saws(self, base_walk, num_samples):\n        \"\"\"Create num_samples copies of the base walk\"\"\"\n        walks = np.tile(base_walk[np.newaxis, :, :], (num_samples, 1, 1))\n        return cp.array(walks)  # Shape: (num_samples, L+1, 2)\n\n    def pivot_move_single(self, walk, L, max_trial):\n        \"\"\"Perform a single pivot move on a single walk on CPU using np.bincount\"\"\"\n        for _ in range(max_trial):\n            k = np.random.randint(1, L)  # Random pivot point\n            g = np.random.randint(0, 4)  # Random symmetry operation (0: rotate90, 1: rotate180, 2: reflect_x, 3: reflect_y)\n\n            # Apply symmetry operation to subwalk\n            subwalk = walk[k:] - walk[k]\n            if g == 0:  # rotate90\n                transformed = np.array([[-y, x] for [x, y] in subwalk])\n            elif g == 1:  # rotate180\n                transformed = np.array([[-x, -y] for [x, y] in subwalk])\n            elif g == 2:  # reflect_x\n                transformed = np.array([[x, -y] for [x, y] in subwalk])\n            else:  # reflect_y\n                transformed = np.array([[-x, y] for [x, y] in subwalk])\n\n            new_walk = np.concatenate([walk[:k], walk[k] + transformed])\n\n            # Collision check using np.bincount on CPU\n            indices = new_walk[:, 0] * self.grid_size + new_walk[:, 1]\n            counts = np.bincount(indices, minlength=self.grid_size * self.grid_size)\n            if np.all(counts <= 1):\n                return new_walk, True\n\n        return walk, False\n\n    def pivot_move_parallel(self, walks, L, max_trial):\n        \"\"\"Perform pivot move on all walks in parallel using CUDA kernel with batching\"\"\"\n        num_samples = walks.shape[0]\n        batch_size = self.batch_size\n        all_collision_flags = cp.zeros(num_samples, dtype=cp.int32)\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            # Extract the current batch of walks\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            collision_flags = cp.zeros(current_batch_size, dtype=cp.int32)\n\n            counts = cp.zeros(current_batch_size * self.grid_size * self.grid_size, dtype=cp.int32)\n            k_values = cp.random.randint(1, L, size=current_batch_size, dtype=cp.int32)\n            g_values = cp.random.randint(0, 4, size=current_batch_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            pivot_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, self.grid_size, max_trial, counts, k_values, g_values, collision_flags)\n            )\n\n            # Update walks with the batch results\n            walks[batch_start:batch_end] = batch_walks_flat.reshape(current_batch_size, L + 1, 2)\n            all_collision_flags[batch_start:batch_end] = collision_flags\n\n            # Free temporary GPU memory\n            del batch_walks, batch_walks_flat, collision_flags, counts, k_values, g_values\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return walks, all_collision_flags\n\n    def compute_atmosphere_parallel(self, walks, L, num_samples):\n        \"\"\"Compute atmosphere counts for all walks in parallel using CUDA kernel with batching\"\"\"\n        batch_size = self.batch_size\n        all_atm_counts = cp.zeros(num_samples, dtype=cp.float32)\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            # Extract the current batch of walks\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            atm_counts = cp.zeros(current_batch_size, dtype=cp.float32)\n            counts = cp.zeros(current_batch_size * self.grid_size * self.grid_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            atmosphere_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, self.grid_size, counts, atm_counts)\n            )\n\n            all_atm_counts[batch_start:batch_end] = atm_counts\n\n            # Free temporary GPU memory\n            del batch_walks, batch_walks_flat, atm_counts, counts\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return all_atm_counts\n\n    def simulate_atmosphere(self, L, num_samples, max_trial, pivot_steps=1):\n        \"\"\"Estimate atmosphere statistics for walks of length L using GPU parallelization\n        pivot_steps: number of pivot moves per sample (1 or L)\n        \"\"\"\n        # Validate pivot_steps\n        if pivot_steps not in [1, L]:\n            raise ValueError(f\"pivot_steps must be 1 or L ({L}), got {pivot_steps}\")\n\n        # Generate a single initial walk\n        walk = self.generate_initial_saw(L)\n        \n        # Thermalization (burn-in) on a single walk on CPU\n        for _ in range(10 * L):\n            walk, _ = self.pivot_move_single(walk, L, max_trial)\n        \n        # Generate num_samples copies of the thermalized walk\n        walks = self.generate_multiple_saws(walk, num_samples)\n\n        # Production run: perform pivot_steps pivot moves per walk\n        for _ in range(pivot_steps):\n            walks, _ = self.pivot_move_parallel(walks, L, max_trial)\n        \n        # Compute atmosphere for all walks\n        atm_counts = self.compute_atmosphere_parallel(walks, L, num_samples)\n        \n        atm_counts = atm_counts.get()\n\n        # Free GPU memory\n        del walks\n        cp.get_default_memory_pool().free_all_blocks()\n\n        return np.mean(atm_counts), np.std(atm_counts) / np.sqrt(len(atm_counts))\n    \n    def estimate_mu(self, num_samples=10000, max_trial=10, pivot_steps_mode='single'):\n        \"\"\"Estimate μ using atmosphere statistics\n        max_trial: max trials before pivot_move() fails to generate a new SAW and returns the same walk \n        pivot_steps_mode: 'single' (1 pivot) or 'multiple' (L pivots)\n        \"\"\"\n        lengths = np.arange(4, self.L_max+1, 2)\n        atm_means = []\n        atm_stds = []\n        \n        print(\"Running SAW simulations for μ estimation on GPU...\")\n        start = time()\n        for L in tqdm(lengths):\n            pivot_steps = 1 if pivot_steps_mode == 'single' else L\n            mean_atm, std_atm = self.simulate_atmosphere(L, num_samples, max_trial, pivot_steps=pivot_steps)\n            atm_means.append(mean_atm)\n            atm_stds.append(std_atm)\n            print(f\"L={L}: ⟨a⟩ = {mean_atm:.3f} ± {std_atm:.3f}\")\n        end = time()\n        \n        atm_means = np.array(atm_means)\n        atm_stds = np.array(atm_stds)\n        def model(n, mu, gamma, c):\n            return mu * (1 + (gamma-1)/n + c/n**2)\n        \n        popt, pcov = curve_fit(model, lengths, atm_means)\n        mu, gamma = popt[0], popt[1]\n        \n        # Plot 1: <a> vs L\n        plt.figure(figsize=(10,6))\n        plt.scatter(lengths, atm_means, label='Simulation Data')\n        x_fit = np.linspace(lengths[0], lengths[-1], 100)\n        plt.plot(x_fit, model(x_fit, *popt), 'r-', \n                label=f'Fit: μ={mu:.6f}, γ={gamma:.6f}')\n        plt.xlabel('L')\n        plt.ylabel('<a>')\n        plt.title(f'Atmosphere Statistics for 2D SAWs (GPU Parallel), N={num_samples}, Time={end-start:.2f}s, mu~{mu:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig('saw_mu_estimation_gpu_parallel_L.png', dpi=300)\n        plt.close()\n        \n        # Plot 2: <a> vs 1/L with benchmark mu\n        benchmark_mu = 2.638158  # Theoretical mu for 2D SAW\n        inv_lengths = 1 / lengths\n        plt.figure(figsize=(10,6))\n        plt.scatter(inv_lengths, atm_means, label='Simulation Data')\n        x_fit_inv = np.linspace(0, inv_lengths[0], 100)\n        plt.plot(x_fit_inv, model(1/x_fit_inv, *popt), 'r-', \n                label=f'Fit: μ={mu:.6f}, γ={gamma:.6f}')\n        plt.axhline(y=benchmark_mu, color='g', linestyle='--', label=f'Benchmark μ={benchmark_mu:.6f}')\n        plt.xlabel('1/L')\n        plt.ylabel('<a>')\n        plt.title(f'Atmosphere Statistics for 2D SAWs: Convergence to μ (GPU Parallel), N={num_samples}, Time={end-start:.2f}s, mu~{mu:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig('saw_mu_estimation_gpu_parallel_inv_L.png', dpi=300)\n        plt.close()\n        \n        return mu, gamma\n\n# Benchmarking\nif __name__ == \"__main__\":\n    simulator = SAWSimulatorGPU(L_max=1000)\n    \n    # Test both modes\n    for mode in ['single', 'multiple']:\n        print(f\"\\nTesting mode: {mode}\")\n        start_time = time()\n        mu, gamma = simulator.estimate_mu(num_samples=10000, max_trial=10, pivot_steps_mode=mode)\n        gpu_time = time() - start_time\n        \n        print(f\"GPU Parallel Version Results (Mode: {mode}):\")\n        print(f\"Estimated μ = {mu:.6f}\")\n        print(f\"Estimated γ = {gamma:.6f}\")\n        print(f\"Computation Time = {gpu_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T17:50:41.761122Z","iopub.execute_input":"2025-04-24T17:50:41.761332Z","execution_failed":"2025-04-25T00:25:30.233Z"}},"outputs":[{"name":"stdout","text":"Grid size: 2001, Batch size: 256\n\nTesting mode: single\nRunning SAW simulations for μ estimation on GPU...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/499 [00:12<1:44:47, 12.63s/it]","output_type":"stream"},{"name":"stdout","text":"L=4: ⟨a⟩ = 2.750 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 2/499 [00:25<1:43:31, 12.50s/it]","output_type":"stream"},{"name":"stdout","text":"L=6: ⟨a⟩ = 2.897 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 3/499 [00:37<1:44:40, 12.66s/it]","output_type":"stream"},{"name":"stdout","text":"L=8: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 4/499 [00:50<1:45:20, 12.77s/it]","output_type":"stream"},{"name":"stdout","text":"L=10: ⟨a⟩ = 2.637 ± 0.009\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 5/499 [01:04<1:49:04, 13.25s/it]","output_type":"stream"},{"name":"stdout","text":"L=12: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 6/499 [01:20<1:54:10, 13.90s/it]","output_type":"stream"},{"name":"stdout","text":"L=14: ⟨a⟩ = 2.039 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 7/499 [01:37<2:03:16, 15.03s/it]","output_type":"stream"},{"name":"stdout","text":"L=16: ⟨a⟩ = 2.984 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 8/499 [01:54<2:08:38, 15.72s/it]","output_type":"stream"},{"name":"stdout","text":"L=18: ⟨a⟩ = 2.924 ± 0.004\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 9/499 [02:12<2:13:10, 16.31s/it]","output_type":"stream"},{"name":"stdout","text":"L=20: ⟨a⟩ = 2.961 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 10/499 [02:30<2:19:02, 17.06s/it]","output_type":"stream"},{"name":"stdout","text":"L=22: ⟨a⟩ = 2.835 ± 0.005\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 11/499 [02:52<2:28:42, 18.28s/it]","output_type":"stream"},{"name":"stdout","text":"L=24: ⟨a⟩ = 2.958 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 12/499 [03:12<2:33:32, 18.92s/it]","output_type":"stream"},{"name":"stdout","text":"L=26: ⟨a⟩ = 3.000 ± 0.000\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 13/499 [03:35<2:42:21, 20.04s/it]","output_type":"stream"},{"name":"stdout","text":"L=28: ⟨a⟩ = 1.980 ± 0.001\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 14/499 [03:59<2:52:09, 21.30s/it]","output_type":"stream"},{"name":"stdout","text":"L=30: ⟨a⟩ = 2.936 ± 0.003\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 15/499 [04:23<2:58:49, 22.17s/it]","output_type":"stream"},{"name":"stdout","text":"L=32: ⟨a⟩ = 2.957 ± 0.002\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 16/499 [04:49<3:07:15, 23.26s/it]","output_type":"stream"},{"name":"stdout","text":"L=34: ⟨a⟩ = 2.945 ± 0.003\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### 2. Recursive method","metadata":{}},{"cell_type":"markdown","source":"### Key implementation details:\n1. to prevent the value $C_{L1} \\times C_{L2}$ from going too large, exceeding the range of float64, we use $log(C_{L1+L2}) = log(C_{L1}) + log(C_{L2}) + log(\\hat{B})$ instead.\n2. we skip the points where $\\hat{B} = 0$ when doing curve_fit.","metadata":{}},{"cell_type":"markdown","source":"#### 1) Continuous L Sampling Approach","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom scipy.optimize import curve_fit\n\n# Define the CUDA kernel for checking if concatenated walks are SAWs\ncheck_saw_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid check_saw_kernel(\n    int* walks,  // Flattened array: [num_samples, L+1, 2]\n    int num_samples, int L, int grid_size,\n    int* counts,  // Global array: [num_samples, grid_size * grid_size]\n    int* is_saw_flags  // Output: 1 if the walk is a SAW, 0 if collision detected\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= num_samples) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Build counts for the walk\n    bool has_collision = false;\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n            has_collision = true;\n            break;\n        }\n        int idx = count_offset + (x * grid_size + y);\n        atomicAdd(&counts[idx], 1);\n        if (counts[idx] > 1) {\n            has_collision = true;\n            break;\n        }\n    }\n\n    // Reset counts\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        int idx = count_offset + (x * grid_size + y);\n        counts[idx] = 0;\n    }\n\n    is_saw_flags[tid] = (has_collision ? 0 : 1);\n}\n''', 'check_saw_kernel')\n\n# Reusing the pivot kernel from the previous implementation\npivot_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid pivot_move_kernel(\n    int* walks,  // Flattened array: [batch_size, L+1, 2]\n    int batch_size, int L, int grid_size, int max_trial,\n    int* counts,  // Global array: [batch_size, grid_size * grid_size]\n    int* k_values,  // Random pivot points\n    int* g_values,  // Random symmetry operations\n    int* collision_flags  // Output: 1 if successful pivot, 0 if failed\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= batch_size) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Get random pivot point and symmetry operation\n    int k = k_values[tid];\n    int g = g_values[tid];\n\n    // Try pivot move up to max_trial times\n    for (int trial = 0; trial < max_trial; trial++) {\n        // Copy walk to temporary array\n        int temp_walk[2002][2];\n        for (int i = 0; i <= L; i++) {\n            temp_walk[i][0] = walks[walk_offset + i * 2];\n            temp_walk[i][1] = walks[walk_offset + i * 2 + 1];\n        }\n\n        // Apply symmetry operation to subwalk (from k to L)\n        int pivot_x = temp_walk[k][0];\n        int pivot_y = temp_walk[k][1];\n        for (int i = k; i <= L; i++) {\n            int dx = temp_walk[i][0] - pivot_x;\n            int dy = temp_walk[i][1] - pivot_y;\n            if (g == 0) {  // rotate90\n                temp_walk[i][0] = pivot_x - dy;\n                temp_walk[i][1] = pivot_y + dx;\n            } else if (g == 1) {  // rotate180\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else if (g == 2) {  // reflect_x\n                temp_walk[i][0] = pivot_x + dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else {  // reflect_y\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y + dy;\n            }\n        }\n\n        // Collision check \n        bool has_collision = false;\n        for (int i = 0; i <= L; i++) {\n            int x = temp_walk[i][0];\n            int y = temp_walk[i][1];\n            if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n                has_collision = true;\n                break;\n            }\n            int idx = count_offset + (x * grid_size + y);\n            atomicAdd(&counts[idx], 1);\n            if (counts[idx] > 1) {\n                has_collision = true;\n                break;\n            }\n        }\n\n        // Reset counts and update walk if no collision\n        if (!has_collision) {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            for (int i = 0; i <= L; i++) {\n                walks[walk_offset + i * 2] = temp_walk[i][0];\n                walks[walk_offset + i * 2 + 1] = temp_walk[i][1];\n            }\n            collision_flags[tid] = 1;\n            return;\n        } else {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                int idx = count_offset + (x * grid_size + y);\n                counts[idx] = 0;\n            }\n            // Update k and g for next trial\n            k = (k + 1) % (L - 1);\n            if (k == 0) k = 1;\n            g = (g + 1) % 4;\n        }\n    }\n    collision_flags[tid] = 0;\n}\n''', 'pivot_move_kernel')\n\nMU_ESTIMATE = 2.638\n\nclass SAWSimulatorGPU:\n    def __init__(self, L_max=1000):\n        self.directions = np.array([[1,0], [-1,0], [0,1], [0,-1]])\n        self.L_max = L_max\n        self.grid_size = 2 * L_max + 1\n        self.batch_size = 256\n        self.known_counts = {\n            1: np.log(4), 2: np.log(12), 3: np.log(36), 4: np.log(100), 5: np.log(284),\n            6: np.log(780), 7: np.log(2172), 8: np.log(5916), 9: np.log(16268),\n            10: np.log(44100), 11: np.log(120292), 12: np.log(324932), 13: np.log(881500),\n            14: np.log(2374444), 15: np.log(6416596), 16: np.log(17245332), 17: np.log(46466676),\n            18: np.log(124658732), 19: np.log(335116620), 20: np.log(897697164),\n            21: np.log(2408806028), 22: np.log(6444560484), 23: np.log(17266613812),\n            24: np.log(46146397316), 25: np.log(123481354908), 26: np.log(329712786220),\n            27: np.log(881317491628)\n        }\n        self.B_estimates = defaultdict(list)\n        print(f\"Grid size: {self.grid_size}, Batch size: {self.batch_size}\")\n\n    def generate_initial_saw(self, L):\n        start_x, start_y = self.L_max, self.L_max\n        walk = np.array([[start_x + i, start_y] for i in range(L+1)], dtype=np.int32)\n        return walk\n\n    def generate_multiple_saws(self, base_walk, num_samples):\n        walks = np.tile(base_walk[np.newaxis, :, :], (num_samples, 1, 1))\n        return cp.array(walks)\n\n    def pivot_move_single(self, walk, L, max_trial=10):\n        for _ in range(max_trial):\n            k = np.random.randint(1, L)\n            g = np.random.randint(0, 4)\n            subwalk = walk[k:] - walk[k]\n            if g == 0:  # rotate90\n                transformed = np.array([[-y, x] for [x, y] in subwalk])\n            elif g == 1:  # rotate180\n                transformed = np.array([[-x, -y] for [x, y] in subwalk])\n            elif g == 2:  # reflect_x\n                transformed = np.array([[x, -y] for [x, y] in subwalk])\n            else:  # reflect_y\n                transformed = np.array([[-x, y] for [x, y] in subwalk])\n            new_walk = np.concatenate([walk[:k], walk[k] + transformed])\n            indices = new_walk[:, 0] * self.grid_size + new_walk[:, 1]\n            counts = np.bincount(indices, minlength=self.grid_size * self.grid_size)\n            if np.all(counts <= 1):\n                return new_walk, True\n        return walk, False\n\n    def thermalize(self, walk, L):\n        for _ in range(10 * L):\n            walk, _ = self.pivot_move_single(walk, L)\n        return walk\n\n    def pivot_move_parallel(self, walks, L, max_trial):\n        num_samples = walks.shape[0]\n        batch_size = self.batch_size\n        all_collision_flags = cp.zeros(num_samples, dtype=cp.int32)\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            collision_flags = cp.zeros(current_batch_size, dtype=cp.int32)\n\n            counts = cp.zeros(current_batch_size * self.grid_size * self.grid_size, dtype=cp.int32)\n            k_values = cp.random.randint(1, L, size=current_batch_size, dtype=cp.int32)\n            g_values = cp.random.randint(0, 4, size=current_batch_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            pivot_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, self.grid_size, max_trial, counts, k_values, g_values, collision_flags)\n            )\n\n            walks[batch_start:batch_end] = batch_walks_flat.reshape(current_batch_size, L + 1, 2)\n            all_collision_flags[batch_start:batch_end] = collision_flags\n\n            del batch_walks, batch_walks_flat, collision_flags, counts, k_values, g_values\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return walks, all_collision_flags\n\n    def check_saw_parallel(self, walks, L, num_samples):\n        batch_size = self.batch_size\n        all_is_saw_flags = cp.zeros(num_samples, dtype=cp.int32)\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            is_saw_flags = cp.zeros(current_batch_size, dtype=cp.int32)\n            counts = cp.zeros(current_batch_size * self.grid_size * self.grid_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            check_saw_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, self.grid_size, counts, is_saw_flags)\n            )\n\n            all_is_saw_flags[batch_start:batch_end] = is_saw_flags\n\n            del batch_walks, batch_walks_flat, is_saw_flags, counts\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return all_is_saw_flags\n\n    def estimate_B(self, L1, L2, num_samples, max_trial=10):\n        # Generate initial walks for L1 and L2\n        walk1_base = self.generate_initial_saw(L1)\n        walk2_base = self.generate_initial_saw(L2)\n\n        # Thermalize the base walks on CPU\n        walk1_base = self.thermalize(walk1_base, L1)\n        walk2_base = self.thermalize(walk2_base, L2)\n\n        # Generate num_samples copies of each walk on GPU\n        walks1 = self.generate_multiple_saws(walk1_base, num_samples)\n        walks2 = self.generate_multiple_saws(walk2_base, num_samples)\n\n        # Perform pivot moves in parallel\n        walks1, _ = self.pivot_move_parallel(walks1, L1, max_trial)\n        walks2, _ = self.pivot_move_parallel(walks2, L2, max_trial)\n\n        # Concatenate the walks: walk1 + (walk2[1:] shifted to connect with walk1)\n        concatenated_walks = cp.zeros((num_samples, L1 + L2 + 1, 2), dtype=cp.int32)\n        for i in range(num_samples):\n            walk1 = walks1[i]\n            walk2 = walks2[i]\n            offset = walk1[-1] - walk2[0] + cp.array([1, 0], dtype=cp.int32)\n            concatenated_walks[i, :L1+1] = walk1\n            concatenated_walks[i, L1+1:] = walk2[1:] + offset\n\n        # Check if concatenated walks are SAWs in parallel\n        L_total = L1 + L2\n        is_saw_flags = self.check_saw_parallel(concatenated_walks, L_total, num_samples)\n\n        # Calculate B_hat as the proportion of valid SAWs, add a small epsilon to avoid log(0)\n        B_hat = cp.mean(is_saw_flags).get()\n        B_hat = max(B_hat, 1e-10)  # Avoid log(0) by setting a minimum value\n        self.B_estimates[(L1, L2)].append(B_hat)\n\n        # Free GPU memory\n        del walks1, walks2, concatenated_walks, is_saw_flags\n        cp.get_default_memory_pool().free_all_blocks()\n\n        return B_hat\n\n    def recursive_estimate(self, L, num_samples=10000):\n        if L in self.known_counts:\n            return self.known_counts[L]\n            \n        L1 = max(k for k in self.known_counts if k <= L//2)\n        L2 = L - L1\n        log_c_L2 = self.recursive_estimate(L2, num_samples) if L2 not in self.known_counts else self.known_counts[L2]\n        B_est = self.estimate_B(L1, L2, num_samples)\n        log_c_L1 = self.known_counts[L1]\n        # Compute log(c_L) = log(B_est) + log(c_L1) + log(c_L2)\n        log_c_L = np.log(B_est) + log_c_L1 + log_c_L2\n        \n        self.known_counts[L] = log_c_L\n        return log_c_L\n\n    def estimate_mu(self, num_samples=10000):\n        # Compute counts for all L up to L_max\n        start = time()\n        for L in tqdm(range(1, self.L_max + 1), desc=\"Estimating counts\"):\n            if L not in self.known_counts:\n                self.recursive_estimate(L, num_samples)\n        end = time()\n        \n        # Prepare data for fitting\n        L_list = np.array(sorted(self.known_counts.keys()))\n        log_c_N = np.array([self.known_counts[L] for L in L_list])\n        # Skip entries where log_c_N is inf or nan\n        valid_indices = np.isfinite(log_c_N)\n        L_list = L_list[valid_indices]\n        log_c_N = log_c_N[valid_indices]\n        if len(L_list) < 3:\n            raise ValueError(\"Not enough valid data points for fitting after removing inf/NaN\")\n        \n        # Fitting function\n        def fitting_func(N, log_mu, A, gamma):\n            return N * log_mu + (gamma - 1) * np.log(N) + A\n        \n        # Curve fitting\n        p0 = [np.log(MU_ESTIMATE), 1.0, 1.344]\n        bounds = ([0, -np.inf, 0], [np.inf, np.inf, np.inf])\n        popt, _ = curve_fit(fitting_func, L_list, log_c_N, p0=p0, bounds=bounds)\n        mu_est = np.exp(popt[0])\n        \n        # Plotting\n        mu_N = [np.exp(log_c / L) for L, log_c in sorted(self.known_counts.items())]\n        \n        plt.figure(figsize=(10, 6))\n        plt.plot(L_list, mu_N[:len(L_list)], 'bo-', label='μ_N')\n        plt.axhline(y=MU_ESTIMATE, color=\"k\", linestyle=\"--\", label=f\"Theoretical μ ≈ {MU_ESTIMATE}\")\n        plt.xlabel('L')\n        plt.ylabel('μ_N')\n        plt.title(f'Recursive Method Estimation(GPU), N={num_samples}, Time={end-start:.2f}s, mu~{mu_est:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig('recursive_mu_vs_l.png')\n        plt.close()\n        \n        return mu_est\n\n# Main execution\nif __name__ == \"__main__\":\n    simulator = SAWSimulatorGPU(L_max=200)\n    start_time = time()\n    mu_final = simulator.estimate_mu(num_samples=10000)\n    gpu_time = time() - start_time\n    print(f\"\\nGPU Recursive Method Results:\")\n    print(f\"Final μ estimate = {mu_final:.7f}\")\n    print(f\"Computation Time = {gpu_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T05:02:47.789328Z","iopub.execute_input":"2025-04-25T05:02:47.789994Z","iopub.status.idle":"2025-04-25T05:10:51.405045Z","shell.execute_reply.started":"2025-04-25T05:02:47.789970Z","shell.execute_reply":"2025-04-25T05:10:51.404223Z"}},"outputs":[{"name":"stdout","text":"Grid size: 401, Batch size: 256\n","output_type":"stream"},{"name":"stderr","text":"Estimating counts: 100%|██████████| 200/200 [08:03<00:00,  2.42s/it]","output_type":"stream"},{"name":"stdout","text":"\nGPU Recursive Method Results:\nFinal μ estimate = 2.6200326\nComputation Time = 483.58 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"#### 2) Discrete L Sampling Approach","metadata":{}},{"cell_type":"markdown","source":"### Key implementation details\n1. discrete L sampling allows further speed-up as L1=L2, thus only one base thermolisation is needed before both walks start doing parallel pivot moves to this same base walk.","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom scipy.optimize import curve_fit\n\n# Define the CUDA kernel for checking if concatenated walks are SAWs\ncheck_saw_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid check_saw_kernel(\n    int* walks,  // Flattened array: [num_samples, L+1, 2]\n    int num_samples, int L, int grid_size,\n    int* counts,  // Global array: [num_samples, grid_size * grid_size]\n    int* is_saw_flags  // Output: 1 if the walk is a SAW, 0 if collision detected\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= num_samples) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Build counts for the walk\n    bool has_collision = false;\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n            has_collision = true;\n            break;\n        }\n        int idx = count_offset + (x * grid_size + y);\n        atomicAdd(&counts[idx], 1);\n        if (counts[idx] > 1) {\n            has_collision = true;\n            break;\n        }\n    }\n\n    // Reset counts\n    for (int i = 0; i <= L; i++) {\n        int x = walks[walk_offset + i * 2];\n        int y = walks[walk_offset + i * 2 + 1];\n        if (x >= 0 && x < grid_size && y >= 0 && y < grid_size) {\n            int idx = count_offset + (x * grid_size + y);\n            counts[idx] = 0;\n        }\n    }\n\n    is_saw_flags[tid] = (has_collision ? 0 : 1);\n}\n''', 'check_saw_kernel')\n\n# Reusing the pivot kernel from the previous implementation\npivot_kernel = cp.RawKernel(r'''\nextern \"C\" __global__\nvoid pivot_move_kernel(\n    int* walks,  // Flattened array: [batch_size, L+1, 2]\n    int batch_size, int L, int grid_size, int max_trial,\n    int* counts,  // Global array: [batch_size, grid_size * grid_size]\n    int* k_values,  // Random pivot points\n    int* g_values,  // Random symmetry operations\n    int* collision_flags  // Output: 1 if successful pivot, 0 if failed\n) {\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= batch_size) return;\n\n    int walk_offset = tid * (L + 1) * 2;\n    int count_offset = tid * grid_size * grid_size;\n\n    // Get random pivot point and symmetry operation\n    int k = k_values[tid];\n    int g = g_values[tid];\n\n    // Try pivot move up to max_trial times\n    for (int trial = 0; trial < max_trial; trial++) {\n        // Copy walk to temporary array\n        int temp_walk[2002][2];\n        for (int i = 0; i <= L; i++) {\n            temp_walk[i][0] = walks[walk_offset + i * 2];\n            temp_walk[i][1] = walks[walk_offset + i * 2 + 1];\n        }\n\n        // Apply symmetry operation to subwalk (from k to L)\n        int pivot_x = temp_walk[k][0];\n        int pivot_y = temp_walk[k][1];\n        for (int i = k; i <= L; i++) {\n            int dx = temp_walk[i][0] - pivot_x;\n            int dy = temp_walk[i][1] - pivot_y;\n            if (g == 0) {  // rotate90\n                temp_walk[i][0] = pivot_x - dy;\n                temp_walk[i][1] = pivot_y + dx;\n            } else if (g == 1) {  // rotate180\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else if (g == 2) {  // reflect_x\n                temp_walk[i][0] = pivot_x + dx;\n                temp_walk[i][1] = pivot_y - dy;\n            } else {  // reflect_y\n                temp_walk[i][0] = pivot_x - dx;\n                temp_walk[i][1] = pivot_y + dy;\n            }\n        }\n\n        // Collision check \n        bool has_collision = false;\n        for (int i = 0; i <= L; i++) {\n            int x = temp_walk[i][0];\n            int y = temp_walk[i][1];\n            if (x < 0 || x >= grid_size || y < 0 || y >= grid_size) {\n                has_collision = true;\n                break;\n            }\n            int idx = count_offset + (x * grid_size + y);\n            atomicAdd(&counts[idx], 1);\n            if (counts[idx] > 1) {\n                has_collision = true;\n                break;\n            }\n        }\n\n        // Reset counts and update walk if no collision\n        if (!has_collision) {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                if (x >= 0 && x < grid_size && y >= 0 && y < grid_size) {\n                    int idx = count_offset + (x * grid_size + y);\n                    counts[idx] = 0;\n                }\n            }\n            for (int i = 0; i <= L; i++) {\n                walks[walk_offset + i * 2] = temp_walk[i][0];\n                walks[walk_offset + i * 2 + 1] = temp_walk[i][1];\n            }\n            collision_flags[tid] = 1;\n            return;\n        } else {\n            for (int i = 0; i <= L; i++) {\n                int x = temp_walk[i][0];\n                int y = temp_walk[i][1];\n                if (x >= 0 && x < grid_size && y >= 0 && y < grid_size) {\n                    int idx = count_offset + (x * grid_size + y);\n                    counts[idx] = 0;\n                }\n            }\n            // Update k and g for next trial\n            k = (k + 1) % (L - 1);\n            if (k == 0) k = 1;\n            g = (g + 1) % 4;\n        }\n    }\n    collision_flags[tid] = 0;\n}\n''', 'pivot_move_kernel')\n\nMU_ESTIMATE = 2.638\n\nclass SAWSimulatorGPU:\n    def __init__(self, L_max=1000):\n        self.directions = np.array([[1,0], [-1,0], [0,1], [0,-1]])\n        self.L_max = L_max\n        self.max_grid_size = 2 * L_max + 1\n        self.batch_size = 16  # Reduced to lower memory usage\n        self.known_counts = {\n            1: np.log(4), 2: np.log(12), 3: np.log(36), 4: np.log(100), 5: np.log(284),\n            6: np.log(780), 7: np.log(2172), 8: np.log(5916), 9: np.log(16268),\n            10: np.log(44100), 11: np.log(120292), 12: np.log(324932), 13: np.log(881500),\n            14: np.log(2374444), 15: np.log(6416596), 16: np.log(17245332), 17: np.log(46466676),\n            18: np.log(124658732), 19: np.log(335116620), 20: np.log(897697164),\n            21: np.log(2408806028), 22: np.log(6444560484), 23: np.log(17266613812),\n            24: np.log(46146397316), 25: np.log(123481354908), 26: np.log(329712786220),\n            27: np.log(881317491628)\n        }\n        self.B_estimates = defaultdict(list)\n        print(f\"Max grid size: {self.max_grid_size}, Batch size: {self.batch_size}\")\n\n    def generate_initial_saw(self, L, grid_size):\n        start_x, start_y = grid_size // 2, grid_size // 2\n        walk = np.array([[start_x + i, start_y] for i in range(L+1)], dtype=np.int32)\n        return walk\n\n    def generate_multiple_saws(self, base_walk, num_samples):\n        walks = np.tile(base_walk[np.newaxis, :, :], (num_samples, 1, 1))\n        return cp.array(walks)\n\n    def pivot_move_single(self, walk, L, max_trial=10):\n        for _ in range(max_trial):\n            k = np.random.randint(1, L)\n            g = np.random.randint(0, 4)\n            subwalk = walk[k:] - walk[k]\n            if g == 0:  # rotate90\n                transformed = np.array([[-y, x] for [x, y] in subwalk])\n            elif g == 1:  # rotate180\n                transformed = np.array([[-x, -y] for [x, y] in subwalk])\n            elif g == 2:  # reflect_x\n                transformed = np.array([[x, -y] for [x, y] in subwalk])\n            else:  # reflect_y\n                transformed = np.array([[-x, y] for [x, y] in subwalk])\n            new_walk = np.concatenate([walk[:k], walk[k] + transformed])\n            # Check for collisions using np.unique\n            unique_points = np.unique(new_walk, axis=0)\n            if len(unique_points) == len(new_walk):  # All points are unique, no collisions\n                return new_walk, True\n        return walk, False\n\n    def thermalize(self, walk, L):\n        for _ in range(10 * L):\n            walk, _ = self.pivot_move_single(walk, L)\n        return walk\n\n    def pivot_move_parallel(self, walks, L, max_trial, grid_size):\n        num_samples = walks.shape[0]\n        batch_size = self.batch_size\n        all_collision_flags = cp.zeros(num_samples, dtype=cp.int32)\n\n        # Free memory before large allocation\n        cp.get_default_memory_pool().free_all_blocks()\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            collision_flags = cp.zeros(current_batch_size, dtype=cp.int32)\n\n            counts = cp.zeros(current_batch_size * grid_size * grid_size, dtype=cp.int32)\n            k_values = cp.random.randint(1, L, size=current_batch_size, dtype=cp.int32)\n            g_values = cp.random.randint(0, 4, size=current_batch_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            pivot_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, grid_size, max_trial, counts, k_values, g_values, collision_flags)\n            )\n\n            walks[batch_start:batch_end] = batch_walks_flat.reshape(current_batch_size, L + 1, 2)\n            all_collision_flags[batch_start:batch_end] = collision_flags\n\n            del batch_walks, batch_walks_flat, collision_flags, counts, k_values, g_values\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return walks, all_collision_flags\n\n    def check_saw_parallel(self, walks, L, num_samples, grid_size):\n        batch_size = self.batch_size\n        all_is_saw_flags = cp.zeros(num_samples, dtype=cp.int32)\n\n        # Free memory before large allocation\n        cp.get_default_memory_pool().free_all_blocks()\n\n        for batch_start in range(0, num_samples, batch_size):\n            batch_end = min(batch_start + batch_size, num_samples)\n            current_batch_size = batch_end - batch_start\n\n            batch_walks = walks[batch_start:batch_end]\n            batch_walks_flat = batch_walks.reshape(current_batch_size * (L + 1) * 2)\n            is_saw_flags = cp.zeros(current_batch_size, dtype=cp.int32)\n            counts = cp.zeros(current_batch_size * grid_size * grid_size, dtype=cp.int32)\n\n            threads_per_block = min(256, current_batch_size)\n            blocks_per_grid = (current_batch_size + threads_per_block - 1) // threads_per_block\n\n            check_saw_kernel(\n                (blocks_per_grid,), (threads_per_block,),\n                (batch_walks_flat, current_batch_size, L, grid_size, counts, is_saw_flags)\n            )\n\n            all_is_saw_flags[batch_start:batch_end] = is_saw_flags\n\n            del batch_walks, batch_walks_flat, is_saw_flags, counts\n            cp.get_default_memory_pool().free_all_blocks()\n\n        return all_is_saw_flags\n\n    def estimate_B(self, L1, L2, num_samples, max_trial=10):\n        # Since L1 == L2 == L in this context, use a single thermalized walk\n        L = L1  # L1 == L2\n        # Set grid size based on current L\n        grid_size = 2 * L + 1\n        # Generate and thermalize a single base walk\n        base_walk = self.generate_initial_saw(L, grid_size)\n        base_walk = self.thermalize(base_walk, L)\n\n        # Generate two sets of num_samples walks from the same thermalized base walk\n        walks1 = self.generate_multiple_saws(base_walk, num_samples)\n        walks2 = self.generate_multiple_saws(base_walk, num_samples)\n\n        # Perform pivot moves in parallel on both sets\n        walks1, _ = self.pivot_move_parallel(walks1, L, max_trial, grid_size)\n        walks2, _ = self.pivot_move_parallel(walks2, L, max_trial, grid_size)\n\n        # Concatenate the walks: walk1 + (walk2[1:] shifted to connect with walk1)\n        cp.get_default_memory_pool().free_all_blocks()  # Free memory before large allocation\n        concatenated_walks = cp.zeros((num_samples, L1 + L2 + 1, 2), dtype=cp.int32)\n        for i in range(num_samples):\n            walk1 = walks1[i]\n            walk2 = walks2[i]\n            offset = walk1[-1] - walk2[0] + cp.array([1, 0], dtype=cp.int32)\n            concatenated_walks[i, :L1+1] = walk1\n            concatenated_walks[i, L1+1:] = walk2[1:] + offset\n\n        # Check if concatenated walks are SAWs in parallel\n        L_total = L1 + L2\n        concat_grid_size = 2 * L_total + 1\n        is_saw_flags = self.check_saw_parallel(concatenated_walks, L_total, num_samples, concat_grid_size)\n\n        # Calculate B_hat as the proportion of valid SAWs, add a small epsilon to avoid log(0)\n        B_hat = cp.mean(is_saw_flags).get()\n        B_hat = max(B_hat, 1e-10)  # Avoid log(0) by setting a minimum value\n        self.B_estimates[(L1, L2)].append(B_hat)\n\n        # Free GPU memory\n        del walks1, walks2, concatenated_walks, is_saw_flags\n        cp.get_default_memory_pool().free_all_blocks()\n\n        return B_hat\n\n    def recursive_estimate(self, L, num_samples=10000):\n        if L in self.known_counts:\n            return self.known_counts[L]\n            \n        L1 = max(k for k in self.known_counts if k <= L//2)\n        L2 = L - L1\n        log_c_L2 = self.recursive_estimate(L2, num_samples) if L2 not in self.known_counts else self.known_counts[L2]\n        B_est = self.estimate_B(L1, L2, num_samples)\n        log_c_L1 = self.known_counts[L1]\n        # Compute log(c_L) = log(B_est) + log(c_L1) + log(c_L2)\n        log_c_L = np.log(B_est) + log_c_L1 + log_c_L2\n        \n        self.known_counts[L] = log_c_L\n        return log_c_L\n\n    def estimate_mu(self, num_samples=10000):\n        # Generate geometric sequence for L: 10, 20, 40, ..., up to L_max\n        L_list = []\n        L = 10\n        while L <= self.L_max:\n            L_list.append(L)\n            L *= 2\n        L_list = np.array(L_list)\n        \n        # Compute counts for L in the geometric sequence\n        start = time()\n        for L in tqdm(L_list, desc=\"Estimating counts\"):\n            if L not in self.known_counts:\n                self.recursive_estimate(L, num_samples)\n        end = time()\n        \n        # Prepare data for fitting\n        log_c_N = np.array([self.known_counts[L] for L in L_list])\n        # Skip entries where log_c_N is inf or nan\n        valid_indices = np.isfinite(log_c_N)\n        L_list = L_list[valid_indices]\n        log_c_N = log_c_N[valid_indices]\n        if len(L_list) < 3:\n            raise ValueError(\"Not enough valid data points for fitting after removing inf/NaN\")\n        \n        # Fitting function\n        def fitting_func(N, log_mu, A, gamma):\n            return N * log_mu + (gamma - 1) * np.log(N) + A\n        \n        # Curve fitting\n        p0 = [np.log(MU_ESTIMATE), 1.0, 1.344]\n        bounds = ([0, -np.inf, 0], [np.inf, np.inf, np.inf])\n        popt, _ = curve_fit(fitting_func, L_list, log_c_N, p0=p0, bounds=bounds)\n        mu_est = np.exp(popt[0])\n        \n        # Plotting\n        mu_N = [np.exp(log_c / L) for L, log_c in sorted(self.known_counts.items()) if L in L_list]\n        \n        plt.figure(figsize=(10, 6))\n        plt.plot(L_list, mu_N, 'bo-', label='μ_N')\n        plt.axhline(y=MU_ESTIMATE, color=\"k\", linestyle=\"--\", label=f\"Theoretical μ ≈ {MU_ESTIMATE}\")\n        plt.xlabel('L')\n        plt.ylabel('μ_N')\n        plt.title(f'Geometric Recursive Method (GPU, Optimized, Unique, Dynamic, LowMem), N={num_samples}, Time={end-start:.2f}s, mu~{mu_est:.4f}')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig('geometric_recursive_optimized_unique_dynamic_lowmem_mu_vs_l.png')\n        plt.close()\n        \n        return mu_est\n\n# Main execution\nif __name__ == \"__main__\":\n    simulator = SAWSimulatorGPU(L_max=2560)\n    start_time = time()\n    mu_final = simulator.estimate_mu(num_samples=10000)\n    gpu_time = time() - start_time\n    print(f\"\\nGPU Geometric Recursive Method (Optimized, Unique, Dynamic, LowMem) Results:\")\n    print(f\"Final μ estimate = {mu_final:.7f}\")\n    print(f\"Computation Time = {gpu_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T08:55:30.977176Z","iopub.execute_input":"2025-04-25T08:55:30.977620Z","iopub.status.idle":"2025-04-25T09:00:26.902580Z","shell.execute_reply.started":"2025-04-25T08:55:30.977597Z","shell.execute_reply":"2025-04-25T09:00:26.901815Z"}},"outputs":[{"name":"stdout","text":"Max grid size: 5121, Batch size: 16\n","output_type":"stream"},{"name":"stderr","text":"Estimating counts: 100%|██████████| 9/9 [04:55<00:00, 32.85s/it]","output_type":"stream"},{"name":"stdout","text":"\nGPU Geometric Recursive Method (Optimized, Unique, Dynamic, LowMem) Results:\nFinal μ estimate = 2.5926828\nComputation Time = 295.82 seconds\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2}]}